import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler


full_data = pd.read_csv("../../data/synthetic/time_series_single_household.csv")
print(len(full_data))


full_data.head(10)


data = full_data.drop(columns=['Index']).copy()


plt.figure(figsize=(40,20), dpi=40)
plt.locator_params(axis='x', nbins=3)
x_ticks = np.arange(0, len(data["Time"]), 200)
plt.xticks(x_ticks)
plt.xticks(fontsize=40)
plt.yticks(fontsize=40)
plt.plot(data["Time"], data["Energy"])
plt.xlabel("Date", fontsize=40)
plt.ylabel("Energy Consumption (kW-h)", fontsize=40)
plt.title("Energy Consumption Single French Household along 4 years", fontsize=40)
plt.show()


# We observed from the above plot that the trend, seasonality and periodicity can be identified. The irregularity are mostly given by the outliers.


rollmean = data["Energy"].rolling(window=365).mean()
rollstd = data["Energy"].rolling(window=365).std()
#print(rollmean, rollstd)


plt.figure(figsize=(40,20), dpi=40)
plt.locator_params(axis='x', nbins=3)
x_ticks = np.arange(0, len(full_data["Time"]), 200)
plt.xticks(x_ticks)
plt.xticks(fontsize=40)
plt.yticks(fontsize=40)
plt.plot(data["Time"], data["Energy"], label='Original', linewidth='5')
mean = plt.plot(data["Time"], rollmean, '-p', color='red', label='Rolling Mean', linewidth='5')
std = plt.plot(data["Time"], rollstd, '-p', color='white', label='Rolling Std', linewidth='5')
plt.xlabel("Date", fontsize=40)
plt.ylabel("Energy Consumption (kW-h)", fontsize=40)
plt.title("Energy Consumption Single French Household along 4 years", fontsize=40)
plt.legend(loc='best', fontsize=40)
plt.show()



# Also we notice that the data show a stationary behaviour (there is not overall increase or decrease)
# The mean and standard deviation show that there is no significant trend across the yearly seasons


# Find better colors to visualize the boxplot
#plt.title("Outliers Identification", fontsize=40)
plt.figure(figsize=(30,20), dpi=40)
plt.boxplot(data['Energy'])
plt.xticks(fontsize=40)
plt.yticks(fontsize=40)
plt.title("Outliers Identification", fontsize=40)
plt.show()
print(data["Energy"].mean())


# we have potentially 8 outliers, but clearly at least seven should be consider as outlier
max_value = 4.0
# The following condition returns a boolean array and the sum() call adds only the true conditions
outliers_number = (data["Energy"] > max_value).sum()
outliers_density = outliers_number/len(data["Energy"])
print(f"The number of outliers is {outliers_number} and the outliers density is: {outliers_density}")



# Outliers removal
# data.loc[data["Energy"] > 4] = data["Energy"].mean()
# plt.figure(figsize=(30,20), dpi=40)
# plt.boxplot(data['Energy'])
# plt.xticks(fontsize=40)
# plt.yticks(fontsize=40)
# plt.title("Outliers Removal", fontsize=40)
# plt.show()
# print(data["Energy"].mean())


# We will use Standard Scaling because the data is not evenly distributed
scaler = StandardScaler()
# to convert a column from dataframe to a numpy array
energy_values = data.iloc[:,1].values
X = scaler.fit_transform(energy_values.reshape(-1,1))
print(X)


# Here the different values of sigma will play a role of one hyperparameter
gaussianx = np.linspace(0,20)
mu1, sigma1 = 10, 0.5
gaussiany1 = np.exp(-(gaussianx - mu1) ** 2 / 2 * sigma1)
mu2, sigma2 = 10, 1
gaussiany2 = np.exp(-(gaussianx - mu2) ** 2 / 2 * sigma2)
mu3, sigma3 = 10, 4
gaussiany3 = np.exp(-(gaussianx - mu3) ** 2 / 2 * sigma3)
plt.plot(gaussianx, gaussiany1, label="sigma=0.5")
plt.plot(gaussianx, gaussiany2, label="sigma=1")
plt.plot(gaussianx, gaussiany3, label="sigma=4")
plt.legend(loc="best")


# Assumption: every point has the same "gaussian influence" across a single month
# Here we define a monthly importance(decay) factor and the sigma hyperparameter
sigma = 1
nm = 12
m = np.zeros(shape=(1,nm))
for i in range(nm):
    m[0,i] = i * 2
    
#XE : XEngineered
XE = np.zeros(shape=(len(X),nm))
Identity = np.ones(shape=(1,nm))
print(len(XE))
for i in range(len(X)):
    XE[i,:] = np.exp(-(X[i] * Identity - m) * (X[i] * Identity - m) / (2 * sigma))
print(XE)


# for time series we should never split the data randomly! All the test data are the last points to consider
# We have 1442 days, two years will be for training, one year for validation and the rest for test 


Xtrain = XE[0:365]
Xval = XE[365:730]
Xtest = XE[1095:]
ytrain = X[0:365]
yval = X[365:730]
ytest = X[1095:]
print("Size of traininig set:" , len(Xtrain),";\tSize of validations set:", len(Xval), ";\tSize of test set: ", len(Xtest))


# From the above we observe that some coefficients have too large values, then we probably will need some regularization techniques


# Linear Regression
lr = LinearRegression().fit(Xtrain, yval)
# Ridge Regression
alpha = 1
lrr = Ridge(alpha).fit(Xtrain, yval)


print("Results from Linear Regression")
print("slope parameters / weight coefficients (lr.coef_):")
print(lr.coef_)
print("intercept parameter / constant term (lr.intercept_):")
print(lr.intercept_)


print("Results from Ridge Regression")
print("slope parameters / weight coefficients (lrr.coef_):")
print(lrr.coef_)
print("intercept parameter / constant term (lrr.intercept_):")
print(lrr.intercept_)


print("Scores for Linear Regression")
print("Training set score: {:.2f}".format(lr.score(Xtrain, ytrain)))
print("Test set score: {:.2f}".format(lr.score(Xval, yval)))

print("Scores for Ridge Regression")
print("Training set score: {:.2f}".format(lrr.score(Xtrain, ytrain)))
print("Test set score: {:.2f}".format(lrr.score(Xval, yval)))


y_valpredict = lrr.predict(Xval)


# print(y_valpredict[0:5])
# print(yval[0:5])
size = len(Xtrain) + len(Xval)
xreal_values = data.iloc[0:size,0].values
yreal = np.concatenate((ytrain, yval))
print(len(data["Time"][0:size]), len(yreal))
# print(np.transpose(yreal), type(np.transpose(yreal)))
# print(np.transpose(xreal_values), type(np.transpose(xreal_values)))


plt.figure(figsize=(40,20), dpi=40)
plt.locator_params(axis='x', nbins=3)
x_ticks = np.arange(0, len(Xtrain) + len(Xval), 200)
plt.xticks(x_ticks)
plt.xticks(fontsize=40)
plt.yticks(fontsize=40)
size = len(Xtrain) + len(Xval)
yreal = np.concatenate((ytrain, yval))
xreal_values = data.iloc[0:size,0].values
plt.plot(xreal_values, yreal)
ypred= lrr.predict(Xval)
ynull = np.zeros(len(ytrain))
ypredicted = np.concatenate((ynull.reshape(-1,1), ypred))
plt.plot(xreal_values, ypredicted)
plt.xlabel("Date", fontsize=40)
plt.ylabel("Energy Consumption (kW-h)", fontsize=40)
plt.title("Energy Consumption Single French Household along first three years", fontsize=40)
plt.show()
